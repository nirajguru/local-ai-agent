# Local AI Agent

This repo is a follow along of https://www.youtube.com/watch?v=E4l91XKQSgw

## Local LLMs
We use ollama to run the inferences of LLM locally. I have used mistral:7b for chat and mxbai-embed for embeddings.

## Vector Search
Vector search is a locally hosted database in ChromaDB.

## Additional notes
I have used `uv` to install dependencies instead of requirements.txt file

### Dependencies
- langchain-ollama
- langchain-chroma
- pandas
- langchain

